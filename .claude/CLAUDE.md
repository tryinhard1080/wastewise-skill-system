# WasteWise Project Instructions

## ğŸ¯ Project Overview

WasteWise is a **skills-based SaaS platform** for waste management optimization in multifamily properties. This is NOT a standard template - it contains specific business logic and critical calculation formulas that MUST be preserved.

**Branding**: "WasteWise by THE Trash Hub" (NEVER "Advantage Waste")

## ğŸ—ï¸ Architecture

### Skills-Based System
- **Dynamic module loading**: Request type determines which skill executes at runtime
- **5 Core Skills**: wastewise-analytics, compactor-optimization, contract-extractor, regulatory-research, batch-extractor
- **Request Flow**: User Request â†’ Request Analyzer â†’ Skill Selector â†’ Skill Executor â†’ Results
- **Admin-only modifications**: Skills are fixed for all users; only admins/developers can update

### Technology Stack
- **Frontend**: Next.js 14 + React 19 + TypeScript + Tailwind CSS + shadcn/ui
- **Backend**: Supabase (PostgreSQL + Auth + Storage + Edge Functions)
- **AI Services**: All via Anthropic (Claude Vision for invoices, Claude Sonnet for regulatory)
- **Reports**: ExcelJS (workbooks) + custom HTML (dashboards)
- **Testing**: Vitest (unit) + Playwright (E2E) + custom evals framework

### Async Job Architecture

**Problem**: AI operations take 30s-5 minutes, exceeding API route timeouts (10s Vercel, 30s self-hosted)

**Solution**: Background job queue with polling-based status checks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€1â”€â”€â–¶ â”‚ POST /api/   â”‚â”€â”€2â”€â”€â–¶ â”‚ analysis_   â”‚
â”‚  (Browser)  â”‚       â”‚ analyze      â”‚       â”‚ jobs table  â”‚
â”‚             â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚              â”‚                      â”‚
â”‚             â”‚              â”‚ 3. Return job_id     â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚             â”‚                                     â”‚
â”‚             â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚             â”‚â”€â”€4â”€â”€â–¶ â”‚ GET /api/    â”‚â”€â”€5â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â”‚             â”‚       â”‚ jobs/[id]    â”‚              â”‚
â”‚             â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚             â”‚              â”‚                      â”‚
â”‚   Repeat    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€6â”€â”€â”€â”˜                      â”‚
â”‚  every 2s   â”‚       (status + progress)           â”‚
â”‚             â”‚                                     â”‚
â”‚             â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚             â”‚       â”‚ Background   â”‚â”€â”€7â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â”‚             â”‚       â”‚ Worker       â”‚              â”‚
â”‚             â”‚       â”‚ (picks up    â”‚              â”‚
â”‚             â”‚       â”‚  pending)    â”‚              â”‚
â”‚             â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚             â”‚              â”‚                      â”‚
â”‚             â”‚              â”‚ 8. Update progress   â”‚
â”‚             â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â”‚             â”‚                                     â”‚
â”‚             â”‚              â”‚ 9. Save results      â”‚
â”‚             â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Client-Side Pattern**:
```typescript
// 1. Start analysis
const { jobId } = await fetch('/api/analyze', {
  method: 'POST',
  body: JSON.stringify({ projectId })
}).then(r => r.json())

// 2. Poll for status (every 2 seconds)
const pollStatus = async () => {
  const job = await fetch(`/api/jobs/${jobId}`).then(r => r.json())

  if (job.status === 'completed') {
    return job.result_data
  } else if (job.status === 'failed') {
    throw new Error(job.error_message)
  } else {
    // Still processing - show progress
    updateProgressBar(job.progress_percent)
    showCurrentStep(job.current_step)
    setTimeout(pollStatus, 2000)
  }
}
```

**Backend Pattern**:
```typescript
// API Route: Start job
export async function POST(req: Request) {
  const { projectId } = await req.json()

  // Create job record
  const { data: job } = await supabase
    .from('analysis_jobs')
    .insert({
      user_id: userId,
      project_id: projectId,
      job_type: 'complete_analysis',
      status: 'pending',
      input_data: { projectId }
    })
    .select()
    .single()

  // Background worker will pick this up
  return Response.json({ jobId: job.id })
}

// API Route: Check status
export async function GET(req: Request, { params }) {
  const { data: job } = await supabase
    .from('analysis_jobs')
    .select('*')
    .eq('id', params.id)
    .single()

  return Response.json(job)
}
```

**Background Worker** (runs in separate process/container):
```typescript
// Continuously poll for pending jobs
while (true) {
  const { data: jobs } = await supabase
    .from('analysis_jobs')
    .select('*')
    .eq('status', 'pending')
    .order('created_at', { ascending: true })
    .limit(1)

  if (jobs.length > 0) {
    await processJob(jobs[0])
  }

  await sleep(1000) // Check every second
}

async function processJob(job: AnalysisJob) {
  try {
    // Mark as processing
    await supabase.rpc('start_analysis_job', { job_id: job.id })

    // Execute skill with progress updates
    const result = await executeSkill(job.job_type, job.input_data, {
      onProgress: async (percent, step) => {
        await supabase.rpc('update_job_progress', {
          job_id: job.id,
          new_progress: percent,
          step_name: step
        })
      }
    })

    // Mark as completed
    await supabase.rpc('complete_analysis_job', {
      job_id: job.id,
      result,
      ai_usage: { /* token counts, costs */ }
    })
  } catch (error) {
    // Mark as failed (with retry logic)
    await supabase.rpc('fail_analysis_job', {
      job_id: job.id,
      error_msg: error.message,
      error_cd: error.code
    })
  }
}
```

**Key Benefits**:
- âœ… No timeout issues (jobs can run for hours if needed)
- âœ… Progress tracking (user sees real-time updates)
- âœ… Error handling (retry logic, failure tracking)
- âœ… Cost tracking (AI token usage per job)
- âœ… Scalability (multiple workers can process jobs in parallel)

### Database Schema
8 core tables: `projects`, `project_files`, `invoice_data`, `haul_log`, `optimizations`, `contract_terms`, `regulatory_compliance`, `ordinance_database`

**CRITICAL TABLE**: `skills_config`
```sql
create table skills_config (
  id uuid primary key default uuid_generate_v4(),
  skill_name text unique not null,
  skill_version text not null,
  conversion_rates jsonb not null,
  thresholds jsonb not null,
  enabled boolean default true,
  last_validated timestamp with time zone
);
```

## ğŸš¨ Critical Business Rules (NEVER VIOLATE)

**Formula Reference**: All calculations MUST use formulas from `WASTE_FORMULAS_REFERENCE.md` (v2.0) - the canonical source of truth.

### Non-Negotiable Thresholds

1. **Compactor Optimization**: Average tons/haul < **6.0** (per WASTE_FORMULAS_REFERENCE.md v2.0)
   - If avg tons < 6.0 AND max interval â‰¤ 14 days â†’ Recommend monitors
   - Target optimization: 8.5 tons/haul

2. **Contamination**: > **3%** of total spend
   - Recommend reduction program if exceeded

3. **Bulk Subscription**: > **$500/month** average
   - Recommend subscription if average > $500

4. **Lease-up Detection**: > **40%** below benchmark
   - NO optimization recommendations if property is in lease-up

### Critical Formulas (MUST MATCH PYTHON)

```typescript
// Yards Per Door - Compactor
yardsPerDoor = (totalTons * 14.49) / units

// Yards Per Door - Dumpster
yardsPerDoor = (qty * size * frequency * 4.33) / units

// Cost Per Door
costPerDoor = monthlyTotal / units

// Capacity Utilization (Compactor)
utilization = (avgTonsPerHaul / 8.5) * 100  // 8.5 = target tons (industry standard)
```

### Conversion Rates (MUST BE CONSISTENT)

**CRITICAL**: These MUST be identical across all skills (per WASTE_FORMULAS_REFERENCE.md):
- **Compactor YPD**: 14.49 (cubic yards per ton: 2000 lbs/ton Ã· 138 lbs/ydÂ³)
- **Dumpster YPD**: 4.33 (weeks per month constant)
- **Target compactor capacity**: 8.5 tons (industry standard midpoint of 8-9)
- **Optimization threshold**: <6.0 tons (canonical per v2.0)

### Formula Reference Protocol

**Single Source of Truth**:
- **Documentation**: `WASTE_FORMULAS_REFERENCE.md` (version controlled, explains derivations)
- **Code**: `lib/constants/formulas.ts` (exported constants used by all calculations)
- **Database**: `skills_config` table (validated on startup, synced with formulas.ts)

**NEVER Hardcode Formula Values**:
```typescript
// âŒ WRONG - Hardcoded threshold
if (avgTons < 6.0) { ... }

// âœ… CORRECT - Import from canonical source
import { COMPACTOR_OPTIMIZATION_THRESHOLD } from '@/lib/constants/formulas'
if (avgTons < COMPACTOR_OPTIMIZATION_THRESHOLD) { ... }
```

**When Formulas Must Change**:
1. Update `WASTE_FORMULAS_REFERENCE.md` with new value and justification
2. Update `lib/constants/formulas.ts` with new constant value
3. Run `FORMULA_CHANGE_CHECKLIST.md` to validate all affected areas
4. Update database seed data and migrations
5. Update all agent documentation (orchestrator, backend, skills, testing)
6. Run full eval suite to ensure calculations still match expected results
7. Update test fixtures and expected values
8. Document the change in git commit with clear rationale

**Validation Requirements**:
- Runtime validation: `validateFormulaConstants()` runs on app startup
- Test validation: Evals compare TypeScript vs Python reference (<0.01% tolerance)
- Database validation: Skills config must match formulas.ts values
- Documentation validation: All agent docs reference formulas.ts, not hardcoded values

### Benchmarks by Property Type

| Property Type | Yards/Door/Week | Cost/Door/Month |
|---------------|-----------------|-----------------|
| Garden-Style  | 2.0-2.5         | $15-25          |
| Mid-Rise      | 1.8-2.3         | $12-22          |
| High-Rise     | 1.5-2.0         | $10-20          |

## ğŸ¤– Agent-Orchestrated Development

### Development Workflow

This project uses **specialized agents** coordinated by an orchestrator:

1. **Orchestrator Agent**: Coordinates all development, manages branches, validates merges
2. **Frontend Agent**: UI components, pages, responsiveness (`frontend/*` branches)
3. **Backend Agent**: API routes, database, AI integrations (`backend/*` branches)
4. **Skills Agent**: Port Python logic, ensure conversion rate consistency (`skills/*` branches)
5. **Testing Agent**: Unit tests, E2E tests, evals (`testing/*` branches)

### GitHub Branch Strategy

**Note**: This repository uses `master` as the main branch (not `main`).

```
master (protected - requires PR + tests + evals)
â”œâ”€â”€ frontend/landing-rebrand
â”œâ”€â”€ frontend/auth-ui
â”œâ”€â”€ frontend/dashboard-shell
â”œâ”€â”€ frontend/project-wizard
â”œâ”€â”€ frontend/processing-page
â”œâ”€â”€ frontend/results-page
â”œâ”€â”€ backend/initial-schema
â”œâ”€â”€ backend/auth-setup
â”œâ”€â”€ backend/claude-vision-extraction
â”œâ”€â”€ backend/regulatory-research
â”œâ”€â”€ backend/report-generation
â”œâ”€â”€ skills/core-system
â”œâ”€â”€ skills/router-executor
â”œâ”€â”€ skills/[skill-name]
â”œâ”€â”€ testing/framework-setup
â””â”€â”€ testing/comprehensive-suite
```

### Merge Protocol

1. Agent creates feature branch
2. Agent commits work
3. Agent opens PR to main (template auto-fills from `.github/PULL_REQUEST_TEMPLATE.md`)
4. **Complete ALL PR checklist items**:
   - Type of change specified
   - Related phase checked
   - Testing completed (unit, TypeScript, lint)
   - **Formula validation** (if calculations changed - CRITICAL!)
   - Database changes documented (if schema changed)
   - Code quality checks passed
   - WasteWise-specific validations (container types, conversion rates)
   - Agent context specified
5. **Automated checks** run (once GitHub Actions configured):
   - Unit tests pass (`pnpm test`)
   - TypeScript compiles (`pnpm tsc --noEmit`)
   - Linting passes (`pnpm lint`)
   - **Evals pass** (calculations match Python within 0.01%)
   - **Conversion rates validated** (must match reference)
6. Self-review or orchestrator reviews
7. Merge to master

**Git Workflow Documentation**: See `docs/git/` for complete workflow guides:
- `GIT_QUICK_REFERENCE.md` - Daily workflow cheatsheet
- `GIT_VISUAL_WORKFLOW.md` - Visual diagrams and examples

## ğŸ”§ MCP Integration

### Chrome DevTools MCP
- **Purpose**: Front-end debugging and performance validation
- **Usage**: Validate responsiveness, check console errors, profile performance
- **Install**: `npm install -g chrome-devtools-mcp`
- **Config**: Added to `.claude/mcp-servers.json`

### When to Use Chrome MCP
- Debugging UI layout issues
- Validating mobile responsiveness
- Performance profiling (Lighthouse audits)
- Checking for console errors
- Automated browser testing

## ğŸ”’ Sandboxing Configuration

### Why Sandbox for WasteWise?

**Security Benefits**:
- âœ… Protection against prompt injection attacks targeting AI agents
- âœ… Automatic blocking of .env, credentials.json, and secrets
- âœ… Network isolation to prevent unauthorized API calls
- âœ… 84% reduction in permission prompts = faster development

**Productivity Benefits**:
- âœ… Agents work autonomously within defined boundaries
- âœ… No interruptions for file operations within project directories
- âœ… Pre-approved network access to Anthropic, Supabase, Upstash

### Quick Start

```
# Enable sandbox with WasteWise defaults
/sandbox
```

This automatically:
- Grants write access to project directories (app, components, lib, tests, docs)
- Denies access to sensitive files (.env, credentials, config.toml)
- Allows network requests to approved domains only
- Excludes git/supabase/docker from sandbox (use standard permissions)

### Sandbox Profiles

WasteWise includes 4 predefined profiles in `.claude/profiles/`:

1. **wastewise-dev.json** (Default)
   - Full project write access
   - All approved APIs
   - For frontend-dev, backend-dev, coder agents

2. **wastewise-testing.json**
   - Test directories only
   - No production databases
   - For tester, reviewer agents

3. **wastewise-docs.json**
   - Documentation directories only
   - No network access needed
   - For documentation work

4. **wastewise-readonly.json**
   - Read-only access
   - Full network for research
   - For Explore, researcher, code-analyzer agents

### Configuration Files

**Main Config**: `.claude/sandbox.json`
- Defines allowed/denied filesystem paths
- Lists approved network domains
- Specifies excluded commands

**Profiles**: `.claude/profiles/*.json`
- Task-specific boundary definitions
- Agent type recommendations
- Security notes and restrictions

### Protected Resources

**Always Denied** (all profiles):
- `.env` and `.env.*` (environment variables)
- `.credentials.json` (OAuth tokens)
- `supabase/config.toml` (database credentials)
- `node_modules/` (dependency modifications)
- `.git/` (version control internals)
- Build artifacts (`.next/`, `dist/`)

**Approved Domains** (dev profile):
- `api.anthropic.com` (Claude AI services)
- `*.supabase.co` (Database and storage)
- `*.upstash.io` (Redis rate limiting)
- `cdn.jsdelivr.net` (Chart.js for reports)
- `api.exa.ai`, `api.tavily.com`, `api.brave.com` (Search APIs)
- `registry.npmjs.org` (Package management)
- `*.github.com` (Version control)

### Violation Monitoring

**Audit Logging**: `lib/observability/sandbox-logger.ts`
- Tracks all boundary violation attempts
- Records approved vs denied access
- Detects suspicious patterns
- Integrates with existing logger

**Access Logs**:
```typescript
import { logFilesystemViolation, getSandboxStats } from '@/lib/observability/sandbox-logger'

// Violations are automatically logged
// View stats via getSandboxStats()
```

### Integration with Security Layers

Sandboxing is **Layer 1** in WasteWise defense-in-depth:

```
Layer 1: Sandbox (filesystem + network isolation)
Layer 2: IAM permissions (tool-level approval)
Layer 3: RLS policies (database-level)
Layer 4: Input sanitization (application-level)
Layer 5: CSP headers (browser-level)
```

All layers work together - sandbox blocks unauthorized access before it reaches other layers.

### Testing Sandbox Compliance

**Test Suite**: `__tests__/security/sandbox-compliance.test.ts`

```bash
# Run sandbox compliance tests
pnpm test __tests__/security/sandbox-compliance.test.ts
```

**Validates**:
- Denied file access actually fails
- Allowed paths work without permission
- Unapproved domains trigger permission requests
- Excluded commands use standard flow

*See docs/SANDBOXING.md for complete configuration guide*

## ğŸ“ Code Quality Standards

### Modularity
- **Max 500 lines per file**
- **Single responsibility** per function/component
- **Clear, descriptive names** (no abbreviations unless industry-standard)

### Testing
- **TDD approach**: Write tests before implementation
- **Evals for calculations**: Every calculation must match Python reference
- **E2E for workflows**: Complete user flows tested end-to-end
- **Performance tests**: Lighthouse score >90

### Documentation
- **Comment complex logic** with "why" not "what"
- **Use file:line references** when discussing code
- **Keep README updated** with setup instructions

### Error Handling
- **Meaningful error messages** for users
- **Graceful failures** - never crash silently
- **Retry logic** for API calls (max 3 attempts)
- **Log errors** for debugging

## ğŸ” Quality Gates & Validation (MANDATORY)

**Added**: 2025-11-14 after Phase 3 critical fixes

**Purpose**: Prevent runtime failures by catching schema/type mismatches at development time

**See**: `.claude/quality-checklist.md` for complete validation steps

### Pre-Development Validation (REQUIRED)

**BEFORE writing code, ALWAYS**:
1. âœ… Read database schema in `supabase/migrations/` for exact constraints
2. âœ… Read API contracts in `app/api/` for response shapes
3. âœ… Import types from `lib/skills/types.ts` (never redefine)
4. âœ… Import constants from `lib/constants/formulas.ts` (never hardcode)

### Agent-Based Development (MANDATORY)

**ALL development MUST use specialized agents** - Never make changes directly.

**Agent Selection**:
- **Frontend changes** â†’ Use `frontend-dev` agent
- **Backend changes** â†’ Use `backend-dev` agent
- **Before ANY commit** â†’ Use `code-analyzer` agent (validates schema, types, API contracts)
- **Complex tasks** â†’ Use `planner` agent first

### Common Pitfalls & Solutions

#### 1. Schema Mismatch âš ï¸ CRITICAL
**Problem**: Form values don't match database CHECK constraints â†’ 100% INSERT failures

âŒ **WRONG**:
```typescript
property_type: 'multifamily'  // Database expects 'Garden-Style'
equipment_type: 'compactor'   // Database expects 'COMPACTOR' (uppercase)
status: 'active'              // Database expects 'draft'
```

âœ… **CORRECT**:
```typescript
// Read supabase/migrations/*.sql FIRST
property_type: 'Garden-Style'  // Exact match to CHECK constraint
equipment_type: 'COMPACTOR'    // Exact case match
status: 'draft'                // Valid enum value
```

#### 2. API Shape Mismatch âš ï¸ CRITICAL
**Problem**: Component expects snake_case, API returns camelCase â†’ SWR breaks

âŒ **WRONG**:
```typescript
interface Job {
  job_type: string           // API returns jobType
  progress_percent: number   // API returns progress.percent
}
```

âœ… **CORRECT**:
```typescript
interface Job {
  jobType: string            // Matches API response
  progress: {
    percent: number          // Nested as API provides
  }
}
```

#### 3. Duplicate Type Definitions âš ï¸ HIGH
**Problem**: Redefining types causes field mismatches

âŒ **WRONG**:
```typescript
interface CompactorResult {
  dsqMonitorCost?: { install: number }  // Skill doesn't return this
}
```

âœ… **CORRECT**:
```typescript
import type { CompactorOptimizationResult } from '@/lib/skills/types'
import { DSQ_MONITOR_INSTALL } from '@/lib/constants/formulas'

// Use imported types and constants
const cost = DSQ_MONITOR_INSTALL
```

### Mandatory Build Checks

#### Pre-Commit (MUST PASS)
```bash
# All must pass with 0 errors
pnpm tsc --noEmit      # TypeScript validation
pnpm lint              # ESLint
pnpm test:unit         # Unit tests
```

#### Never Use
```typescript
// âŒ CRITICAL - These hide errors
typescript: { ignoreBuildErrors: true }
eslint: { ignoreDuringBuilds: true }
```

### Validation Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Start Feature   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Read Schema &   â”‚  â† MANDATORY FIRST STEP
â”‚ API Contracts   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use Agent       â”‚  â† Frontend/Backend/Skills
â”‚ (Not Direct)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Analyzer   â”‚  â† BEFORE COMMIT
â”‚ Agent Review    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tsc --noEmit    â”‚  â† MUST PASS
â”‚ (0 errors)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Commit          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phased Quality Enforcement (NEW - Phase 1.5)

**Philosophy**: Start light, add rigor progressively as codebase matures.

**Phase 1.5 (Foundation - Current)**:
- âœ… Core types defined (Skill interface, SkillContext, SkillResult)
- âœ… Base skill class with common functionality
- âœ… Structured logging (logger)
- âœ… Standardized error types (AppError hierarchy)
- âœ… Basic metrics tracking (in-memory)
- âœ… Async job infrastructure (analysis_jobs table)
- â¸ï¸ **Not enforced yet**: Strict type coverage, 100% test coverage, mandatory evals

**Phase 2 (Implementation)**:
- Implement concrete skills using BaseSkill class
- Use logger and error types consistently
- Track metrics for skill executions
- Begin writing unit tests (no coverage requirements yet)

**Phase 3 (Validation)**:
- Run evals on completed skills
- Fix calculation discrepancies
- Add integration tests for API routes
- Enforce <0.01% deviation tolerance

**Phase 4 (Production Readiness)**:
- âœ… 100% test coverage for calculations
- âœ… All evals passing
- âœ… Lighthouse score >90
- âœ… Security audit complete
- âœ… Error handling comprehensive
- âœ… Monitoring integrated (replace console with service)

**Current Expectations (Phase 1.5)**:
- **DO**: Use provided types and base classes when creating new skills
- **DO**: Use logger for important events (errors, job progress)
- **DO**: Use standardized error types in API routes
- **DO**: Track metrics for AI usage and execution time
- **DON'T**: Worry about perfect test coverage yet
- **DON'T**: Block on missing evals (write placeholder tests)
- **DON'T**: Over-engineer observability (console logging is fine for now)

**Example of Gradual Adoption**:

```typescript
// Phase 1.5: Basic implementation with new infrastructure
import { BaseSkill } from '@/lib/skills/base-skill'
import { logger } from '@/lib/observability/logger'
import { metrics } from '@/lib/observability/metrics'
import type { SkillContext, SkillResult } from '@/lib/skills/types'

export class MySkill extends BaseSkill<MyResult> {
  readonly name = 'my-skill'
  readonly version = '1.0.0'
  readonly description = 'Example skill'

  protected async executeInternal(context: SkillContext): Promise<MyResult> {
    // Use logger for key events
    logger.info('Starting skill execution', { skillName: this.name, projectId: context.projectId })

    // Track metrics
    const timerId = metrics.startTimer('skill.my-skill.execution')

    try {
      // ... business logic here ...

      const result = { /* ... */ }

      metrics.stopTimer(timerId)
      metrics.increment('skill.my-skill.success')

      return result
    } catch (error) {
      metrics.stopTimer(timerId)
      metrics.increment('skill.my-skill.failed')

      logger.error('Skill execution failed', error as Error, { skillName: this.name })
      throw error
    }
  }
}

// Phase 2: Add proper validation
async validate(context: SkillContext): Promise<ValidationResult> {
  // ... add skill-specific validation ...
}

// Phase 3: Add comprehensive tests and evals
// __tests__/skills/my-skill.test.ts
// lib/evals/my-skill-eval.ts

// Phase 4: Production hardening
// - Add performance monitoring
// - Integrate with error tracking service (Sentry)
// - Add rate limiting
// - Security audit
```

**Benefits of This Approach**:
- âœ… Move fast without being blocked by testing requirements
- âœ… Build good patterns from the start (types, errors, logging)
- âœ… Avoid technical debt (structured foundation in place)
- âœ… Can tighten enforcement later (types already exist)
- âœ… Focus on business logic first (UX and calculations)

## ğŸ§ª Testing & Validation

### The /validate Command

**Philosophy**: "If `/validate` passes, WasteWise is production-ready"

**Purpose**: Provides 100% confidence that WasteWise works correctly through comprehensive automated testing across five critical phases.

**Quick Start**:
```bash
# Full validation (all 5 phases) - Use before PRs
pnpm validate

# Fast validation (skip E2E tests) - Use before commits
pnpm validate:skip-e2e

# Run specific phase only
pnpm validate:phase=1  # Linting
pnpm validate:phase=2  # Type checking
pnpm validate:phase=3  # Style checking
pnpm validate:phase=4  # Unit tests
pnpm validate:phase=5  # E2E tests
```

**Complete Documentation**: See `docs/VALIDATION.md` for full guide.

### The Five Validation Phases

#### Phase 1: Linting
- **Command**: `pnpm lint`
- **Purpose**: Enforce code quality, catch common errors
- **Expected**: 0 errors, 0 warnings

#### Phase 2: Type Checking
- **Command**: `pnpm tsc --noEmit`
- **Purpose**: Ensure type safety across codebase
- **Expected**: 0 type errors
- **Note**: TypeScript strict mode enabled

#### Phase 3: Style Checking
- **Command**: `pnpm prettier --check .`
- **Purpose**: Maintain consistent code formatting
- **Expected**: All files properly formatted
- **Fix**: Run `pnpm prettier --write .`

#### Phase 4: Unit Testing
- **Command**: `pnpm test:unit`
- **Purpose**: Test calculations, utilities, business logic
- **Expected**: All tests pass, <0.01% deviation from Python reference
- **Critical Tests**:
  - `lib/evals/` - Calculation accuracy
  - `__tests__/skills/` - Skills logic
  - `__tests__/security/` - Security hardening (XSS, file upload, RLS)

#### Phase 5: End-to-End Testing
- **Command**: `pnpm test:e2e`
- **Purpose**: Test complete user workflows
- **Expected**: All 66 E2E tests pass across 8 test suites
- **Workflows Tested**:
  1. User Registration & Login
  2. Create Project
  3. Upload Files
  4. Run Analysis (with job processing)
  5. View Results & Download Reports
  6. Error Handling

### Test Coverage

**Unit Tests** (Phase 4):
- **Skills**: 100% coverage for all 5 skills
- **Calculations**: <0.01% deviation from Python reference
- **Security**: XSS, file upload, RLS, rate limiting

**E2E Tests** (Phase 5):
- **66 total tests** across 8 test suites
- **Complete workflows**: Auth, projects, uploads, analysis, results
- **Performance**: Lighthouse audits, load testing
- **Responsiveness**: 6 viewport sizes

**Integration Tests**:
- **API endpoints**: All routes tested with real data
- **Database**: RLS policies, cascade deletes, constraints
- **External services**: Anthropic AI, Supabase Storage

### Evals Framework

**Purpose**: Validate TypeScript calculations match Python reference

```typescript
// lib/evals/calculation-evals.ts

// Compare TypeScript output vs Python reference
export async function evaluateCompactorOptimization(
  input: CompactorData,
  expectedOutput: OptimizationResult
): Promise<EvalResult> {
  const tsResult = await calculateCompactorOptimization(input);
  const tolerance = 0.0001; // 0.01% tolerance

  return {
    pass: Math.abs(tsResult.savings - expectedOutput.savings) < tolerance,
    tsValue: tsResult.savings,
    pythonValue: expectedOutput.savings,
    difference: tsResult.savings - expectedOutput.savings
  };
}
```

**Run Evals**:
```bash
pnpm eval  # Standalone evals
pnpm validate:phase=4  # Evals + all unit tests
```

### Success Criteria

**If all 5 phases pass**:
- âœ… WasteWise is production-ready
- âœ… All critical user workflows tested
- âœ… All calculations verified accurate
- âœ… All security measures validated
- âœ… Safe to deploy

**If any phase fails**:
- âŒ Do NOT deploy to production
- âŒ Fix failing tests first
- âŒ Re-run `/validate` until all pass

### When to Run Validation

- âœ… **Before every commit**: `pnpm validate:skip-e2e` (30 seconds)
- âœ… **Before every PR**: `pnpm validate` (3-5 minutes)
- âœ… **After major changes**: `pnpm validate`
- âœ… **Before deploying**: `pnpm validate`
- âœ… **In CI/CD**: Automated on PR and merge to master

### Continuous Validation

**Pre-merge checks** (automated in CI/CD):
```yaml
# .github/workflows/validate-merge.yml
- Phase 1: Linting (pnpm lint)
- Phase 2: Type checking (pnpm tsc --noEmit)
- Phase 3: Style checking (pnpm prettier --check .)
- Phase 4: Unit tests + evals (pnpm test:unit)
- Phase 5: E2E tests (pnpm test:e2e)
- Block merge if any fail
```

**Git Pre-commit Hook** (optional):
```bash
# .husky/pre-commit
pnpm validate:skip-e2e || exit 1
```

### Troubleshooting

**Common Issues**:
- Supabase not running â†’ `supabase start`
- Database migrations â†’ `supabase db reset`
- E2E timeouts â†’ Increase timeout in `playwright.config.ts`
- Calculation evals failing â†’ Verify Python reference matches
- Rate limiting tests â†’ Check Upstash Redis configured

**Phase-Specific**:
- Phase 1 failures â†’ `pnpm lint --fix`
- Phase 2 failures â†’ Review TypeScript errors, fix type mismatches
- Phase 3 failures â†’ `pnpm prettier --write .`
- Phase 4 failures â†’ Check test output, verify evals pass
- Phase 5 failures â†’ Run `pnpm test:e2e:debug` to see browser

**Full Troubleshooting Guide**: See `docs/VALIDATION.md`

## ğŸ“¦ File Structure

```
wastewise-saas/
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ CLAUDE.md (this file)
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ orchestrator.md
â”‚   â”‚   â”œâ”€â”€ frontend-agent.md
â”‚   â”‚   â”œâ”€â”€ backend-agent.md
â”‚   â”‚   â”œâ”€â”€ skills-agent.md
â”‚   â”‚   â””â”€â”€ testing-agent.md
â”‚   â””â”€â”€ mcp-servers.json
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ login/
â”‚   â”‚   â”œâ”€â”€ signup/
â”‚   â”‚   â””â”€â”€ forgot-password/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â”œâ”€â”€ new/
â”‚   â”‚   â”œâ”€â”€ [id]/
â”‚   â”‚   â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”‚   â””â”€â”€ results/
â”‚   â”œâ”€â”€ settings/
â”‚   â”œâ”€â”€ pricing/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â”œâ”€â”€ extract-invoices/
â”‚   â”‚   â”œâ”€â”€ analyze-optimizations/
â”‚   â”‚   â”œâ”€â”€ regulatory-research/
â”‚   â”‚   â””â”€â”€ generate-reports/
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â””â”€â”€ page.tsx (landing)
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/ (shadcn components)
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ wizard/
â”‚   â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ results/
â”‚   â””â”€â”€ charts/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ skills/
â”‚   â”‚   â”œâ”€â”€ registry.ts
â”‚   â”‚   â”œâ”€â”€ executor.ts
â”‚   â”‚   â”œâ”€â”€ analyzer.ts
â”‚   â”‚   â”œâ”€â”€ validator.ts
â”‚   â”‚   â””â”€â”€ skills/
â”‚   â”‚       â”œâ”€â”€ wastewise-analytics.ts
â”‚   â”‚       â”œâ”€â”€ compactor-optimization.ts
â”‚   â”‚       â”œâ”€â”€ contract-extractor.ts
â”‚   â”‚       â”œâ”€â”€ regulatory-research.ts
â”‚   â”‚       â””â”€â”€ batch-extractor.ts
â”‚   â”œâ”€â”€ calculations/
â”‚   â”‚   â”œâ”€â”€ compactor-optimization.ts
â”‚   â”‚   â”œâ”€â”€ yards-per-door.ts
â”‚   â”‚   â””â”€â”€ benchmarks.ts
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ anthropic-client.ts
â”‚   â”‚   â”œâ”€â”€ invoice-extractor.ts
â”‚   â”‚   â””â”€â”€ ordinance-extractor.ts
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ excel-generator.ts
â”‚   â”‚   â””â”€â”€ html-generator.ts
â”‚   â”œâ”€â”€ evals/
â”‚   â”‚   â”œâ”€â”€ calculation-evals.ts
â”‚   â”‚   â””â”€â”€ test-data/
â”‚   â”œâ”€â”€ supabase/
â”‚   â”‚   â”œâ”€â”€ client.ts
â”‚   â”‚   â””â”€â”€ server.ts
â”‚   â”œâ”€â”€ validations/
â”‚   â”‚   â””â”€â”€ schemas.ts
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ formatting.ts
â”œâ”€â”€ supabase/
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ 00001_initial_schema.sql
â”‚   â””â”€â”€ seed.sql
â”œâ”€â”€ __tests__/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ waste-skills-complete/ (Python reference implementations)
â”œâ”€â”€ .env.local (git-ignored)
â”œâ”€â”€ .env.template
â””â”€â”€ package.json
```

## ğŸ” Environment Variables

```bash
# .env.local (never commit)

# Supabase
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_KEY=

# AI Services (all Anthropic)
ANTHROPIC_API_KEY=

# Search (TBD: Exa, Tavily, or cache-first)
SEARCH_API_KEY=

# App
NEXT_PUBLIC_APP_URL=http://localhost:3000
NODE_ENV=development
```

## ğŸš€ Quick Commands

```bash
# Validation (Most Important)
pnpm validate               # Full validation (all 5 phases) - Before PRs
pnpm validate:skip-e2e      # Fast validation (skip E2E) - Before commits
pnpm validate:phase=1       # Run specific phase only

# Development
pnpm dev                    # Start dev server
pnpm test                   # Run all tests
pnpm test:unit              # Unit tests only
pnpm test:e2e               # E2E tests only
pnpm eval                   # Run calculation evals

# Database (Supabase CLI)
supabase start              # Start local Supabase
supabase db reset           # Reset database
supabase migration new [name]  # Create migration

# Git Workflow (Agent-based)
git checkout -b frontend/feature-name
# ... make changes ...
git add .
git commit -m "feat(frontend): add feature"
git push origin frontend/feature-name
# Create PR, wait for checks, merge
```

## ğŸ“Š Success Metrics

**Calculation Accuracy**:
- All formulas match Python reference within 0.01%
- Conversion rates consistent across all skills
- Evals pass on every commit

**Performance**:
- Lighthouse score >90
- Page load time <2s
- Mobile responsive (375px-1440px)

**Code Quality**:
- 100% test coverage for calculations
- No console errors
- All linters passing
- TypeScript strict mode

**User Experience**:
- Complete workflow: signup â†’ create â†’ process â†’ results â†’ download
- Processing time: <5 minutes
- Download both reports (Excel + HTML) successfully
- Reports match exact specifications from template

## ğŸ¯ Current Phase

**Phase**: 7 - Integration Testing & Production Deployment
**Status**: In Progress (85% Complete)
**Started**: 2025-11-17

### Completed Phases (0-6)
- âœ… **Phase 0**: Foundation (Next.js, Supabase, Auth)
- âœ… **Phase 1**: Core Infrastructure (Error handling, logging, database schema)
- âœ… **Phase 2.1**: Compactor Optimization Vertical Slice
- âœ… **Phase 2.2**: API Endpoints with rate limiting
- âœ… **Phase 3-5**: Report generation, async jobs, workers
- âœ… **Phase 6**: Complete Analytics Integration (Excel/HTML reports, frontend results page)

### Phase 7 Progress
**Goal**: Validate entire system through integration testing and prepare for production deployment

**Completed**:
- âœ… Worker startup validation (environment checks)
- âœ… Test data seed script (test user, 250-unit property, 6 invoices, 22 haul logs)
- âœ… All systems running (Supabase, dev server, worker)
- âœ… Automated test framework setup

**In Progress**:
- ğŸ”„ Manual E2E workflow testing (login â†’ analyze â†’ results â†’ download)
- â³ API endpoint integration tests
- â³ Frontend responsiveness validation
- â³ Performance & load testing

**Remaining**:
- Security validation (auth, RLS, input validation)
- Production deployment configuration
- Monitoring & health checks setup
- Documentation (API docs, deployment guide)

### Test Credentials (Local Development)
```bash
# Test User
Email: test@wastewise.local
Password: TestPassword123!

# Test Project
ID: d82e2314-7ccf-404e-a133-0caebb154c7e
Name: Riverside Gardens Apartments
Units: 250 units
Equipment: COMPACTOR
Location: Austin, TX
Data: 6 invoices (Jan-Jun 2025), 22 haul log entries
```

### Production Readiness: 85%
- âœ… Complete end-to-end workflow implemented
- âœ… Real Excel and HTML report generation
- âœ… Async job processing with background workers
- âœ… Frontend results page with downloads
- âœ… Database migrations and RPC functions
- â³ Comprehensive integration testing needed
- â³ Production deployment configuration needed
- â³ Monitoring and health checks needed

**Next Phase**: Phase 8 - Production Launch & User Feedback

---

**Last Updated**: 2025-11-22 (Added comprehensive validation system)
**Version**: 7.1.0
**Maintained By**: Orchestrator Agent
